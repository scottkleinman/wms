{
  "content": "\n\nWednesday 17 December 2014 05.33 EST\tUK universities prepare to find out how research activity has been rated\tVice-chancellors will discover results of research excellence framework, which determines distribution of \u00a32bn in funding\tChristmas will be coming a little earlier for Britain\u2019s university vice-chancellors this year, when they unwrap the results of the research excellence framework (Ref) that will determine the distribution of \u00a32bn in research funding, ahead of its public unveiling on Thursday.; For nearly two years, academics and administrators in university departments across Britain have been engaged in the massive exercise conducted by the higher education funding councils, which seeks to rate each university\u2019s research activity by subject. The highest-rated departments \u2013 those said to have produced \u201cworld-leading\u201d or \u201cinternationally excellent\u201d research \u2013 will be rewarded with the lion\u2019s share of the \u00a32bn in recurring funding.; But there is more at stake than just money: those departments with coveted four-star ratings will use that fact to attract staff and recruit students, as well as using the distinction to win industry backing.; While the league tables of successful departments and subject areas will be dominated by the \u201cgolden triangle\u201d of Cambridge, London and Oxford, further down the lists there will be nervous times for universities such as York, Essex and Bath, which will be hoping to match the share of funding they won during the last similar exercise, conducted in 2008.; At the same time, senior common rooms in Glasgow and Birmingham universities are hoping for a major improvement on their showing in 2008, when some prestigious institutions failed to display their research output to best effect. Glasgow, in particular, could only make the top 40 in the 2008 research assessment exercise, despite its membership of the Russell Group of 24 leading research universities.; Critics of the Ref say that it ties up huge numbers of staff on what is in effect a \u00a350m bookkeeping exercise, with more than 1,000 experts sifting through 1,911 subject submissions by 155 higher education institutions, rating 52,000 staff who produced 191,000 pieces of published research.; This time the difference is that each department has to show that its best research has made a difference to the rest of the world, with 25% of a department\u2019s overall rating coming from case studies designed to show \u201coutstanding\u201d or \u201cvery considerable\u201d impact.; Nick Hillman, director of the Higher Education Policy Institute, said: \u201cThe impact case studies are likely to produce a few surprises, and may shake things up a bit. It\u2019s the first time that universities have had to show the impact of their work, and there\u2019s a lot of uncertainty about the best way to tackle it.\u201d; For scientists and medical researchers, showing impact may be straightforward: new drugs approved for treatment, breakthroughs turned into products. Scientists at Imperial College, London \u2013 expected to be one of the biggest success stories in this year\u2019s Ref \u2013 have included the pioneering use of specially bred mosquitoes to understand and control the spread of disease.; For departments in the arts and humanities, impact is less clear-cut. Some universities have taken an innovative approach, such as University College London\u2019s school of European languages. It has offered the department\u2019s Nordic Noir Crime Fiction Book Club, which sought to capitalise on popular Nordic television dramas such as The Killing and The Bridge, \u201cproviding background information and facilitating an informed discussion about Scandinavian culture and society\u201d, according to the university.; Social scientists will be trying to show that their research helped influence public debate and shaped legislation or political decisions, with quoting of a piece of research by an MP in the House of Commons, for example, counting as high impact.; The uncertain effect of the impact case studies has tempered an otherwise strong mood of optimism, with most universities confident that they will have done better than in 2008. But it is each institution\u2019s relative performance that counts when the funding is divided up.; The Ref\u2019s judges and panel members will also award star ratings ranging from four to none for each university\u2019s subject output, which counts for 65% of the overall grade, with \u201cenvironment\u201d, which is mainly postgraduate teaching, accounting for 15%.; For university departments the most difficult decisions will have been which members of staff to include in the Ref, and which pieces of research to forward for assessment. More staff included will mean higher funding, but fewer staff means tighter quality control and a greater chance of a coveted four- or three-star rating.; The Ref results are only the first of a two-part process: vice-chancellors will not discover how much they have won or lost until the four national funding councils publish their formula for distributing the funds. But most observers expect it to be little changed from the 2008 allocation, which only awarded support to four and three star-rated departments, based on their number of active research staff.",
  "metapath": "Corpus,guardian-h,ProcessedData",
  "name": "guardian-2014-h-254",
  "namespace": "we1sv2.0",
  "title": "\n\nWednesday 17 ..."
}